{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "import pickle\n",
                "import numpy as np\n",
                "import random\n",
                "import os\n",
                "from tqdm import tqdm\n",
                "\n",
                "import torch\n",
                "from torch import nn, optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.tensorboard import SummaryWriter\n",
                "\n",
                "from transformers import GPT2LMHeadModel\n",
                "from transformers import Trainer, TrainingArguments\n",
                "from transformers import GPT2Tokenizer\n",
                "\n",
                "DEVICE = \"cpu\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "# By order of size:\n",
                "# gpt-2\n",
                "# gpt-2-medium\n",
                "# gpt-2-large\n",
                "# gpt-2-xl\n",
                "\n",
                "MODEL_VERSION = \"gpt2\"\n",
                "\n",
                "#model = GPT2LMHeadModel.from_pretrained(MODEL_VERSION)\n",
                "model = GPT2LMHeadModel.from_pretrained(\"./checkpoints/Aug07_17-13-42_psvbogvnh/epoch-4\")\n",
                "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_VERSION)\n",
                "model.to(DEVICE)\n",
                "\n",
                "print(\"Done\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model.eval()\n",
                "\n",
                "no_prompt = torch.tensor([[tokenizer.eos_token_id]])\n",
                "wayne_verse_prompt = torch.tensor([[tokenizer.eos_token_id] + tokenizer.encode(\"[Verse 1: Lil Wayne]\")])\n",
                "wayne_song_prompt = torch.tensor([[tokenizer.eos_token_id] + tokenizer.encode(\"===\\nArtist & title: Lil Wayne I Love Computers\")])\n",
                "\n",
                "generation_output = model.generate(\n",
                "    wayne_song_prompt.to(DEVICE),\n",
                "    return_dict_in_generate=True,\n",
                "    output_scores=True,\n",
                "    max_length=128,\n",
                "    num_beams=1,\n",
                "    do_sample=True,\n",
                ")\n",
                "print(tokenizer.decode(generation_output.sequences[0]))"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "c1cc69e61c0f1c7ade8df0f2994e582e7c1f2c57d1ec192a0baf9f96b7739d9d"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}